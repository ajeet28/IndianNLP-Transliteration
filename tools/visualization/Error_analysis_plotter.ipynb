{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Error_analysis_plotter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJsPmhP3Js1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://noto-website-2.storage.googleapis.com/pkgs/NotoSansDevanagari-hinted.zip\n",
        "!mkdir fonts\n",
        "!unzip /content/NotoSansDevanagari-hinted.zip -d fonts/\n",
        "!mv fonts/* /usr/share/fonts/truetype/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sKss3lMqqZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import sys\n",
        "import os\n",
        "import json\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import numpy as np\n",
        "\n",
        "def list_system_font():\n",
        "    from matplotlib import font_manager\n",
        "    font_paths = font_manager.findSystemFonts()\n",
        "    font_objects = font_manager.createFontList(font_paths)\n",
        "    font_names = [f.name for f in font_objects]\n",
        "    print (sorted(font_names))\n",
        "\n",
        "list_system_font()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6-enaCOudNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_best_reference(pred_list, truth_list, topk = 3):\n",
        "    def LCS_length(s1, s2):\n",
        "        m = len(s1)\n",
        "        n = len(s2)\n",
        "        # An (m+1) times (n+1) matrix\n",
        "        C = [[0] * (n+1) for i in range(m+1)]\n",
        "        for i in range(1, m+1):\n",
        "            for j in range(1, n+1):\n",
        "                if s1[i-1] == s2[j-1]:\n",
        "                    C[i][j] = C[i-1][j-1] + 1\n",
        "                else:\n",
        "                    C[i][j] = max(C[i][j-1], C[i-1][j])\n",
        "        return C[m][n]\n",
        "\n",
        "    best_ref = truth_list[0]\n",
        "    best_cand = pred_list[0]\n",
        "    best_ref_lcs = LCS_length(pred_list[0], truth_list[0])\n",
        "    for cand in pred_list[1:topk]:\n",
        "        for ref in truth_list[1:]:\n",
        "            lcs = LCS_length(cand, ref)\n",
        "            if (len(ref) - 2*lcs) < (len(best_ref) - 2*best_ref_lcs):\n",
        "                best_ref = ref\n",
        "                best_cand = cand\n",
        "                best_ref_lcs = lcs\n",
        "\n",
        "    return best_cand, best_ref\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfMf4q1MugJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def generate_confusion(pred_file, truth_file, vocab):\n",
        "    '''\n",
        "    Returns a pandas dataframe with confusion matrix values\n",
        "    '''\n",
        "    with open(pred_file) as f:\n",
        "        pred_data = json.load(f)\n",
        "    with open(truth_file) as f:\n",
        "        truth_data = json.load(f)\n",
        "\n",
        "    conf_df = pd.DataFrame(0, columns=vocab, index=vocab)\n",
        "    for k in pred_data:\n",
        "        pred_list = pred_data[k]\n",
        "        truth_list = truth_data[k]\n",
        "        best_pred, best_truth = find_best_reference(pred_list, truth_list)\n",
        "\n",
        "        max_len_ = max(len(best_pred), len(best_truth))\n",
        "        pred = best_pred + ( \"_\" * (max_len_-len(best_pred)) )\n",
        "        truth = best_truth + ( \"_\" * (max_len_-len(best_truth)) )\n",
        "\n",
        "        for p,t in zip(pred, truth):\n",
        "            conf_df.loc[p][t] += 1\n",
        "\n",
        "    return conf_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpEBCM5LunyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "## -----------------------------------------------------------------------------\n",
        "\n",
        "dgri_seg = {\n",
        "    \"vowel\": ['ऄ', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ','ऍ', 'ऎ', 'ए', 'ऐ',\n",
        "              'ऑ', 'ऒ', 'ओ', 'औ','ऋ','ॠ','ऌ','ॡ','ॲ', 'ॐ', ],\n",
        "    \"cons\" : ['क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण',\n",
        "              'त', 'थ', 'द', 'ध', 'न', 'ऩ', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ऱ', 'ल',\n",
        "              'ळ', 'ऴ', 'व', 'श', 'ष', 'स', 'ह', 'क़', 'ख़', 'ग़', 'ज़', 'ड़', 'ढ़', 'फ़', 'य़'],\n",
        "    \"vow_symb\": [ '्', 'ा', 'ि', 'ी', 'ु', 'ू', 'ॅ', 'ॆ', 'े', 'ै', 'ॉ', 'ॊ', 'ो', 'ौ',\n",
        "                  'ृ', 'ॄ', 'ॢ', 'ॣ', 'ँ', 'ं', 'ः', '़', '॑', 'ऽ', ]\n",
        "}\n",
        "\n",
        "dgri_unicodes =  dgri_seg[\"vowel\"] + dgri_seg[\"cons\"] + dgri_seg[\"vow_symb\"]+ [\n",
        "    chr(0x200c), # ZeroWidth-NonJoiner U+200c\n",
        "    chr(0x200d), # ZeroWidthJoiner U+200d\n",
        "    \"_\", # empty pading\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKmLZydgujoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def plot_confusion(conf_df, show_chars = None, remove_empty = False, save_prefix=\"\", title = \"Plot\"):\n",
        "    plot_df = conf_df\n",
        "\n",
        "    ## Drop rows/columns full of zeros\n",
        "    if remove_empty:\n",
        "        plot_df = plot_df.loc[:,(df != 0).any(axis=0)] #remove columns\n",
        "        plot_df = plot_df.loc[(df!=0).any(axis=1), :] #remove rows\n",
        "\n",
        "\n",
        "    if isinstance(show_chars, list):\n",
        "        show_chars_ = {}\n",
        "        show_chars_['x'], show_chars_['y'] = show_chars, show_chars\n",
        "\n",
        "    ## Remove unnecessary char counts\n",
        "    if show_chars:\n",
        "        plot_df = plot_df.drop(\"_\", axis = 0)\n",
        "        plot_df = plot_df.drop(\"_\", axis = 1)\n",
        "\n",
        "        dfrows = list(plot_df.index.values)\n",
        "        dfcols = list(plot_df.columns.values)\n",
        "        plot_df.loc[\"other\",:] = 0\n",
        "        plot_df.loc[:, \"other\"] = 0\n",
        "\n",
        "        for r in dfrows: #prediction\n",
        "            if r not in show_chars['y']:\n",
        "                plot_df.loc[\"other\",:] += plot_df.loc[r,:]\n",
        "                plot_df = plot_df.drop(r, axis = 0)\n",
        "\n",
        "        for c in dfcols: #truth\n",
        "            if c not in show_chars['x']:\n",
        "                # plot_df.loc[:, \"other\"] += plot_df.loc[:, c]\n",
        "                plot_df = plot_df.drop(c, axis = 1)\n",
        "\n",
        "    ## Clip Values\n",
        "    # plot_df = plot_df.clip(0, 100)\n",
        "\n",
        "    ## Fonts and Layout ----------\n",
        "    font_sz = 20; fig_sz = (20, 30)\n",
        "    plt.figure(figsize = fig_sz)\n",
        "    font_path = '/usr/share/fonts/truetype/NotoSansDevanagariUI-Condensed.ttf'\n",
        "    fontprop = fm.FontProperties(fname=font_path, size= font_sz)\n",
        "    # ---\n",
        "\n",
        "    conf_plot = sns.heatmap(plot_df, annot=False)\n",
        "\n",
        "    conf_plot.yaxis.set_ticklabels(conf_plot.yaxis.get_ticklabels(),\n",
        "                                    ha='right', rotation=0, fontproperties=fontprop)\n",
        "    conf_plot.xaxis.set_ticklabels(conf_plot.xaxis.get_ticklabels(),\n",
        "                                    ha='left', rotation=0, fontproperties=fontprop)\n",
        "\n",
        "    # conf_plot.tick_params(axis='both', which='major', pad=10)\n",
        "    plt.ylabel('Predicted Character', fontsize = font_sz)\n",
        "    plt.xlabel('True Character', fontsize = font_sz)\n",
        "    plt.title (title, fontsize = font_sz)\n",
        "    plt.show()\n",
        "\n",
        "    conf_plot.figure.savefig( save_prefix +title+\"plot.png\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWLGYrWMHwYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "truth_file = \"/content/Toggled-GomEn_ann1_test.json\"\n",
        "pred_file =\"/content/pred_GomEn_ann1_test.json\"\n",
        "\n",
        "df = generate_confusion(pred_file, truth_file, dgri_unicodes)\n",
        "\n",
        "for c in dgri_unicodes:\n",
        "    df[c][c] = 0\n",
        "\n",
        "plot_confusion(df, {'x': dgri_seg['vowel'], 'y': dgri_unicodes} ,\n",
        "                    save_prefix= \"\", title = \"Vowels\");\n",
        "plot_confusion(df, {'x': dgri_seg['cons'], 'y': dgri_unicodes} , remove_empty = True,\n",
        "                    save_prefix= \"\", title = \"Consonants\");\n",
        "plot_confusion(df,  {'x': dgri_seg['vow_symb'], 'y': dgri_unicodes} ,\n",
        "                    save_prefix= \"\", title = \"Vowel_Matras\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCP38f4ivi8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}